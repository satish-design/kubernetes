KUBERNETES INSTALLATION AND CLUSTER SETUP (YouTube channel name : Easytech_9S)

Pre-requisites : Ubuntu Linux 
                 Ubuntu t2.medium 1 instance (Master "Control Plane Node" )
                 Ubunte t2.micro 2 instances (Worker Nodes)

{{{{{ Execute On 3 ubuntu instances }}}}}

sudo swapoff -a

cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.ipv4.ip_forward = 1
EOF

sudo sysctl --system

sysctl net.ipv4.ip_forward

sudo apt-get update

sudo apt-get install ca-certificates curl

sudo install -m 0755 -d /etc/apt/keyrings

sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc

sudo chmod a+r /etc/apt/keyrings/docker.asc

# Add the repository to Apt sources:

 echo   "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \
  $(. /etc/os-release && echo "${UBUNTU_CODENAME:-$VERSION_CODENAME}") stable" |   sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

sudo apt-get update

sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin

sudo docker run hello-world

containerd config default |   sed 's/SystemdCgroup = false/SystemdCgroup = true/' |   sed 's/sandbox_image = "registry.k8s.io\/pause:3.6"/sandbox_image = "registry.k8s.io\/pause:3.9"/' |   sudo tee /etc/containerd/config.toml

sudo systemctl restart containerd
 sudo systemctl status containerd
 sudo apt-get install -y apt-transport-https ca-certificates curl gpg
 curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.32/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
 echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.32/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list
sudo apt-get update

sudo apt-get install -y kubelet kubeadm kubectl

kubelet --version
kubeadm version
kubectl version --client

{{{{Execute Below Commands On Master/Contol plane node }}}}

kubeadm init
kubectl get nodes

kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/calico.yaml

kubeadm token create --print-join-command

Give The Generated Token on Worker Nodes .

KUBERNETES ARCHITECTURE 

Kubernetes is a container orchestration platform that helps you deploy, manage, and scale containerized applications. Its architecture is split into two major parts
1. Control Plane (Master Node)

>>>API Server (kube-apiserver)
The front-end of the Kubernetes control plane.
Exposes APIs that users, tools, and components interact with (like kubectl or the dashboard).
All communication goes through here.

>>>etcd
A consistent, distributed key-value store.
Stores all cluster data: configuration, state, secrets, etc.
Highly available and fault-tolerant.

>>>Scheduler (kube-scheduler)
Assigns new pods to nodes based on available resources, policies, and constraints.
Considers CPU, memory, affinity rules, etc.

>>>Controller Manager (kube-controller-manager)
Runs different controllers that handle tasks such as:
Node controller (monitors node health)
Replication controller (maintains correct number of pod replicas)
Endpoints controller (manages service endpoints)


2. Worker Node (Minions)
Kubelet

A small agent running on each worker node.
Communicates with the API Server.
Starts, stops, and manages containers via the container runtime.

Kube Proxy
Manages network traffic into and out of the node.
Enables service discovery and load balancing.
Handles rules for forwarding traffic to the correct pod IP and port.

Container Runtime
Software that runs containers.
Examples: Docker, containerd, CRI-O.
Kubelet talks to this to start and manage containers.

ðŸ”¹ 3. Pods
The smallest deployable unit in Kubernetes.
A pod can have one or more containers that share the same network and storage.
Kubernetes manages pods, not containers directly.

ðŸ”„ How It All Works Together:
A user runs kubectl apply -f okso.yaml.
The API Server receives this and stores the desired state in etcd.
The Scheduler picks a suitable worker node.
The Kubelet on that node pulls the container image via the runtime.
The Controller Manager ensures the deployment stays healthy (e.g., recreates pods if they crash).
The Kube Proxy manages traffic to/from the pods.







